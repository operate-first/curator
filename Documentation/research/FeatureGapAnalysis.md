# Feature Gap Analysis

### Purpose



The purpose of this document is to layout differences and similarities between Curator and Project Koku. The goal in assessing the feature gaps is to see how Curator can leverage services utilized by Koku to fulfill the metering requirements for users within the MOC.



### What is Curator trying to solve?



There are several services that provide OCP cluster data to customers. Curator currently utilizes Operator Metering, one of the existing services to provide resource utilization data to end users. There is a current initiative to help infrastructure owners, [Deploying Masu](https://koku.readthedocs.io/en/latest/install.html#deploying-masu)project leaders, and individual end users on Open Clouds track infrastructure usage over time. The purpose of Curator is to resolve this need by providing easily accessible weekly, daily, and monthly reports to end users for viewing and downloading.



### What will the Curator project need?

Koku is a cost management/reporting tool that can be accessed through an API or a web user interface with capabilities to identify and report on the cost and resource usage data generated by different sources such as AWS and OCP. As part of a previous field study we explored Project Koku as a way for an admin to retrieve resource utilization metrics for an OCP cluster within the MOC.

The initial stage of Curator is to provide resource consumption metrics for all applications running on OpenShift instances in the Mass Open Cloud. Korekuta within Koku seems to utilize ansible and korekuta-operator (the upstream of the cost-mgmt-operator) to retrieve and upload OCP usage data. Since both projects rely on Prometheus as the default datasource in order to collect in-cluster information, we are looking to have Curator leverage Project Koku in order to use the same reporting service. Currently the Curator backend retrieves metrics from Openshift Metering API to report to the front end. Queries are included to process daily, weekly and monthly reports. Curator would like to build on the service utilized by Project Koku to collect OCP cluster data in order to fulfill our unique use case.

### Establishing Collection, Processing, and Storage

There are several systems within Koku that the team has researched to see specifically how the data is retrieved, processed, and shared within Koku. There are several subsystems we would like to understand (and potentially leverage) while building the Curator. The systems we would like to adapt (if applicable) from Koku are data gathering and collection (through Prometheus from an OCP cluster to our backend), data querying and processing, and lastly data storage (how is data maintained and managed). We are primarily focusing on the part of Koku that deals with managing costs on Openshift Container Platform rather than a public cloud like AWS.

### Data collection -

For retrieving OCP cluster usage data, there needs to be a way to configure the target OCP cluster to collect resource usage metrics and provide it to the Koku backend. Koku currently utilizes koku-metrics-operator, a community version of the cost-mgmt-operator to produce cost management reports. This operator essentially collects metrics needed for cost management using the metering-operator to create cost management reports. From our research, the steps here seem to be to have OCP cluster installed with the metering-operator along with Koku’s provided configurations for reporting-operator within the Metering namespace. The reporting-operator collects data from Prometheus into Presto and exposes routes through a HTTP API. As part of the subsequent upload phase, Koku then utilizes a script with an Ansible playbook to set up network connectivity to the OCP cluster, collect the usage data from metering-operator endpoints, and upload to Koku through Red Hat Insights Client.

Curator already utilizes a similar approach to data collection from OCP clusters as Koku. Similar to Koku’s setup phase, Curator is using the URL of the route exposed by the reporting operator in the Operator Metering namespace to collect data from Prometheus. As part of its next steps Curator also aims to establish a similar upload phase as that of Koku’s. The things to keep in mind in designing this part of Curator’s subsystem (that differs from Koku from a use case point of view) confirm that utilizing Red Hat Insights Client does not upload any user metadata to Red Hat Insights servers.

### Data Processing-

This is one of the components in which Curator differs from Project Koku. For the scope of this document, we are focusing on data and metrics retrieved from OCP clusters as sources (as opposed to AWS or other public clouds). The goal for Curator is to report on cluster activity through metrics on CPU, Memory, Storage, and Network through utilizing standard and custom reports provided on Openshift Metering. Koku reports on similar metrics for the OCP source with additional processing on creating a computational and cost related summary of data points. In terms of metrics, Curator solely aims to report on daily, weekly, and monthly resource usage data at different levels of the cluster with no cost model added to the metrics.

### Data Storage-

In the current Curator implementation, there is no dedicated storage or database in place for reports collected. Reports generated in the Hive metastore are directly accessed through the reporting-operator API for processing in the backend. This method will be changed in the future with a database in order to reduce duplication in reports as well as reduce time in data management. One option to change this and configure persistent storage would be to leverage Koku’s PostgreSQL backend and create a local database container.

### How does Curator differ from Koku’s services?

Curator currently provides resource usage for infrastructure in the Open Clouds. This means that there is no cost model applied on top of metrics collected. The initial metric collection has been based on data retrieved from predefined report-queries that come with the metering-operator installation. These metrics are cpu, memory, and volume data at the cluster, pod, node and namespace level. Curator also differs from Koku’s services since this will be a tool intended to provide resource data to both administrators and all other end users who are working on projects in the open cloud. Additionally, it will be reporting on applications running on Openshift bare metal within the MOC. Later phases will aim to create one metering system for both OpenStack and OpenShift in one place. The goal for Curator is to fulfill the need of the MOC to allow infrastructure owners and researchers to have a simple way to access their projects’ resource usage information.
